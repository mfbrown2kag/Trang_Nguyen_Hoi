import streamlit as st
import re
from collections import Counter
import nltk
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64

import pickle
from gen import Answer_Question_From_Documents

# ==== 1. Táº£i mÃ´ hÃ¬nh tá»« file ====
with open("model/model_check_email.pkl", "rb") as f:
    model = pickle.load(f)

print("âœ… ÄÃ£ táº£i mÃ´ hÃ¬nh tá»« file 'model.pkl'")

class Input:
    def __init__(self, user : str) -> None:
        self.user : str = user
    def run(self) -> str:
        predictions = model.predict(self.user)
        ans = Answer_Question_From_Documents(self.user,predictions)
        return ans     

# Cáº¥u hÃ¬nh trang
st.set_page_config(
    page_title="Email Analyzer",
    page_icon="ğŸ“§",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS tÃ¹y chá»‰nh
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.1);
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 0.5rem 0;
    }
    .analysis-section {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 10px;
        margin: 1rem 0;
        border-left: 4px solid #1f77b4;
    }
    .positive { color: #28a745; }
    .negative { color: #dc3545; }
    .neutral { color: #6c757d; }
</style>
""", unsafe_allow_html=True)

def analyze_email_content(email_text):
    """PhÃ¢n tÃ­ch ná»™i dung email"""


def create_wordcloud(text):
    """Táº¡o wordcloud tá»« vÄƒn báº£n"""
    wordcloud = WordCloud(
        width=800, 
        height=400, 
        background_color='white',
        colormap='viridis',
        max_words=100
    ).generate(text)
    
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    
    # Chuyá»ƒn Ä‘á»•i thÃ nh base64 Ä‘á»ƒ hiá»ƒn thá»‹ trong Streamlit
    buf = io.BytesIO()
    plt.savefig(buf, format='png', bbox_inches='tight', dpi=300)
    buf.seek(0)
    img_str = base64.b64encode(buf.read()).decode()
    plt.close()
    
    return img_str

def main():
    # Header
    st.markdown('<h1 class="main-header">ğŸ“§ Email Analyzer</h1>', unsafe_allow_html=True)
    st.markdown("### PhÃ¢n tÃ­ch vÃ  Ä‘Ã¡nh giÃ¡ ná»™i dung email")
    
    # Sidebar
    with st.sidebar:
        st.header("âš™ï¸ CÃ i Ä‘áº·t")
        st.markdown("---")
        
        # TÃ¹y chá»n phÃ¢n tÃ­ch
        analysis_options = st.multiselect(
            "Chá»n loáº¡i phÃ¢n tÃ­ch:",
            ["Sentiment Analysis", "Word Frequency", "Text Statistics", "Emotion Keywords", "Word Cloud"],
            default=["Sentiment Analysis", "Text Statistics", "Word Cloud"]
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“Š ThÃ´ng tin")
        st.markdown("""
        **Email Analyzer** giÃºp báº¡n:
        - PhÃ¢n tÃ­ch cáº£m xÃºc cá»§a email
        - Thá»‘ng kÃª tá»« vá»±ng vÃ  cÃ¢u
        - TÃ¬m tá»« khÃ³a quan trá»ng
        - ÄÆ°a ra gá»£i Ã½ cáº£i thiá»‡n
        """)
    
    # Main content
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“ Nháº­p ná»™i dung email")
        email_content = st.text_area(
            "Nháº­p ná»™i dung email cáº§n phÃ¢n tÃ­ch:",
            height=300,
            placeholder="Nháº­p ná»™i dung email cá»§a báº¡n vÃ o Ä‘Ã¢y..."
        )
        
        if st.button("ğŸ” PhÃ¢n tÃ­ch", type="primary", use_container_width=True):
            if email_content.strip():
                with st.spinner("Äang phÃ¢n tÃ­ch..."):
                    analysis_result = analyze_email_content(email_content)
                    
                    if analysis_result:
                        st.success("âœ… PhÃ¢n tÃ­ch hoÃ n táº¥t!")
                        
                        # Hiá»ƒn thá»‹ káº¿t quáº£
                        display_results(analysis_result, email_content, analysis_options)
            else:
                st.error("âŒ Vui lÃ²ng nháº­p ná»™i dung email Ä‘á»ƒ phÃ¢n tÃ­ch!")
    
    with col2:
        st.subheader("ğŸ“‹ HÆ°á»›ng dáº«n")
        st.markdown("""
        1. **Nháº­p email**: Copy vÃ  paste ná»™i dung email vÃ o Ã´ vÄƒn báº£n
        2. **Chá»n phÃ¢n tÃ­ch**: TÃ¹y chá»n loáº¡i phÃ¢n tÃ­ch trong sidebar
        3. **Nháº¥n phÃ¢n tÃ­ch**: Xem káº¿t quáº£ chi tiáº¿t
        4. **Äá»c gá»£i Ã½**: Cáº£i thiá»‡n email dá»±a trÃªn phÃ¢n tÃ­ch
        """)
        
        st.markdown("---")
        st.markdown("### ğŸ’¡ Máº¹o viáº¿t email")
        st.markdown("""
        - **Ngáº¯n gá»n**: 50-125 tá»«
        - **RÃµ rÃ ng**: Má»™t Ã½ chÃ­nh má»—i Ä‘oáº¡n
        - **Lá»‹ch sá»±**: Sá»­ dá»¥ng ngÃ´n ngá»¯ chuyÃªn nghiá»‡p
        - **Call-to-action**: NÃªu rÃµ hÃ nh Ä‘á»™ng mong muá»‘n
        """)

def display_results(analysis, email_content, analysis_options):
    """Hiá»ƒn thá»‹ káº¿t quáº£ phÃ¢n tÃ­ch"""
    
    # Metrics row
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <h3>ğŸ“Š Tá»«</h3>
            <h2>{analysis['word_count']}</h2>
            <p>tá»•ng cá»™ng</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <h3>ğŸ“ CÃ¢u</h3>
            <h2>{analysis['sentence_count']}</h2>
            <p>tá»•ng cá»™ng</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <h3>ğŸ“ KÃ½ tá»±</h3>
            <h2>{analysis['char_count']}</h2>
            <p>tá»•ng cá»™ng</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        st.markdown(f"""
        <div class="metric-card">
            <h3>ğŸ¯ Sentiment</h3>
            <h2 class="{analysis['sentiment_color']}">{analysis['sentiment']}</h2>
            <p>Score: {analysis['sentiment_score']:.2f}</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Detailed analysis
    if "Sentiment Analysis" in analysis_options:
        st.markdown("---")
        st.subheader("ğŸ˜Š PhÃ¢n tÃ­ch cáº£m xÃºc")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Sentiment gauge
            fig = go.Figure(go.Indicator(
                mode = "gauge+number+delta",
                value = analysis['sentiment_score'],
                domain = {'x': [0, 1], 'y': [0, 1]},
                title = {'text': "Sentiment Score"},
                delta = {'reference': 0},
                gauge = {
                    'axis': {'range': [-1, 1]},
                    'bar': {'color': "darkblue"},
                    'steps': [
                        {'range': [-1, -0.3], 'color': "lightgray"},
                        {'range': [-0.3, 0.3], 'color': "yellow"},
                        {'range': [0.3, 1], 'color': "lightgreen"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 0
                    }
                }
            ))
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # Subjectivity chart
            fig = px.bar(
                x=['Subjectivity'],
                y=[analysis['subjectivity_score']],
                title="Äá»™ chá»§ quan",
                color=[analysis['subjectivity_score']],
                color_continuous_scale='viridis'
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
    
    if "Text Statistics" in analysis_options:
        st.markdown("---")
        st.subheader("ğŸ“ˆ Thá»‘ng kÃª vÄƒn báº£n")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Word statistics
            stats_data = {
                'Metric': ['Tá»« tá»•ng cá»™ng', 'Tá»« duy nháº¥t', 'Tá»« trung bÃ¬nh/cÃ¢u', 'KÃ½ tá»± (cÃ³ khoáº£ng tráº¯ng)', 'KÃ½ tá»± (khÃ´ng khoáº£ng tráº¯ng)'],
                'Value': [
                    analysis['word_count'],
                    analysis['unique_words'],
                    f"{analysis['avg_sentence_length']:.1f}",
                    analysis['char_count'],
                    analysis['char_count_no_spaces']
                ]
            }
            df_stats = pd.DataFrame(stats_data)
            st.dataframe(df_stats, use_container_width=True)
        
        with col2:
            # Sentence length distribution
            if analysis['sentence_lengths']:
                fig = px.histogram(
                    x=analysis['sentence_lengths'],
                    title="PhÃ¢n bá»‘ Ä‘á»™ dÃ i cÃ¢u",
                    labels={'x': 'Sá»‘ tá»«', 'y': 'Sá»‘ cÃ¢u'}
                )
                fig.update_layout(height=300)
                st.plotly_chart(fig, use_container_width=True)
    
    if "Word Frequency" in analysis_options:
        st.markdown("---")
        st.subheader("ğŸ”¤ Táº§n suáº¥t tá»« vá»±ng")
        
        if analysis['word_freq']:
            words, freqs = zip(*analysis['word_freq'])
            fig = px.bar(
                x=list(words),
                y=list(freqs),
                title="Top 10 tá»« phá»• biáº¿n nháº¥t",
                labels={'x': 'Tá»«', 'y': 'Táº§n suáº¥t'}
            )
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
    
    if "Emotion Keywords" in analysis_options:
        st.markdown("---")
        st.subheader("ğŸ˜Š Tá»« khÃ³a cáº£m xÃºc")
        
        col1, col2 = st.columns(2)
        
        with col1:
            if analysis['found_positive']:
                st.markdown("**âœ… Tá»« tÃ­ch cá»±c:**")
                for word in set(analysis['found_positive']):
                    st.markdown(f"- {word}")
            else:
                st.info("KhÃ´ng tÃ¬m tháº¥y tá»« tÃ­ch cá»±c")
        
        with col2:
            if analysis['found_negative']:
                st.markdown("**âŒ Tá»« tiÃªu cá»±c:**")
                for word in set(analysis['found_negative']):
                    st.markdown(f"- {word}")
            else:
                st.info("KhÃ´ng tÃ¬m tháº¥y tá»« tiÃªu cá»±c")
    
    if "Word Cloud" in analysis_options:
        st.markdown("---")
        st.subheader("â˜ï¸ Word Cloud")
        
        # Táº¡o wordcloud
        img_str = create_wordcloud(email_content)
        st.markdown(f'<img src="data:image/png;base64,{img_str}" width="100%">', unsafe_allow_html=True)
    
    # Recommendations
    st.markdown("---")
    st.subheader("ğŸ’¡ Gá»£i Ã½ cáº£i thiá»‡n")
    
    recommendations = []
    
    if analysis['sentiment_score'] < -0.2:
        recommendations.append("ğŸ¯ **Cáº£i thiá»‡n tone**: Email cÃ³ váº» tiÃªu cá»±c, hÃ£y sá»­ dá»¥ng ngÃ´n ngá»¯ tÃ­ch cá»±c hÆ¡n")
    
    if analysis['avg_sentence_length'] > 20:
        recommendations.append("ğŸ“ **RÃºt ngáº¯n cÃ¢u**: CÃ¢u quÃ¡ dÃ i, hÃ£y chia thÃ nh nhiá»u cÃ¢u ngáº¯n hÆ¡n")
    
    if analysis['word_count'] < 20:
        recommendations.append("ğŸ“Š **Bá»• sung ná»™i dung**: Email quÃ¡ ngáº¯n, hÃ£y thÃªm chi tiáº¿t cáº§n thiáº¿t")
    
    if analysis['word_count'] > 200:
        recommendations.append("âœ‚ï¸ **TÃ³m táº¯t**: Email quÃ¡ dÃ i, hÃ£y tÃ³m táº¯t nhá»¯ng Ä‘iá»ƒm chÃ­nh")
    
    if analysis['subjectivity_score'] > 0.8:
        recommendations.append("âš–ï¸ **CÃ¢n báº±ng**: Email quÃ¡ chá»§ quan, hÃ£y thÃªm thÃ´ng tin khÃ¡ch quan")
    
    if not recommendations:
        recommendations.append("âœ… **Tuyá»‡t vá»i**: Email cá»§a báº¡n Ä‘Ã£ Ä‘Æ°á»£c viáº¿t tá»‘t!")
    
    for rec in recommendations:
        st.markdown(f"- {rec}")

if __name__ == "__main__":
    main() 