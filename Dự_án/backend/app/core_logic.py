"""
Core logic module for Email Guardian
Extracts email analysis functionality for reuse across different interfaces
"""

import pickle
import os
from .gen import Answer_Question_From_Documents

class EmailAnalyzer:
    """Core email analysis engine"""
    
    def __init__(self, model_path="model/model_check_email.pkl"):
        """Initialize the analyzer with ML model"""
        self.model_path = model_path
        self.model = None
        self.load_model()
    
    def load_model(self):
        """Load the ML model from file"""
        try:
            # Adjust path based on current working directory
            if os.path.exists(self.model_path):
                with open(self.model_path, "rb") as f:
                    self.model = pickle.load(f)
                print(f"‚úÖ Model loaded from {self.model_path}")
            else:
                # Try alternative path
                alt_path = os.path.join("backend", self.model_path)
                if os.path.exists(alt_path):
                    with open(alt_path, "rb") as f:
                        self.model = pickle.load(f)
                    print(f"‚úÖ Model loaded from {alt_path}")
                else:
                    raise FileNotFoundError(f"Model file not found: {self.model_path}")
        except Exception as e:
            print(f"‚ùå Error loading model: {e}")
            raise
    
    def analyze_email(self, email_text):
        """
        Analyze email text and return classification with AI explanation
        
        Args:
            email_text (str): The email content to analyze
            
        Returns:
            dict: Analysis results including classification, confidence, and explanation
        """
        if not self.model:
            raise RuntimeError("Model not loaded")
        
        if not email_text or not email_text.strip():
            raise ValueError("Email text cannot be empty")
        
        try:
            # Get ML model prediction
            predictions = self.model.predict([email_text])
            raw_classification = predictions[0] if predictions else "unknown"
            
            # Map to Vietnamese classification names
            classification_map = {
                # English labels
                'safe': 'An to√†n',
                'spam': 'Spam',
                'phishing': 'L·ª´a ƒë·∫£o',
                'suspicious': 'ƒê√°ng ng·ªù',
                'malware': 'Ph·∫ßn m·ªÅm ƒë·ªôc h·∫°i',
                'unknown': 'C·∫ßn xem x√©t th√™m',
                'notification': 'Th√¥ng b√°o',
                'invoice': 'H√≥a ƒë∆°n',
                'promotion': 'Khuy·∫øn m√£i',
                # Vietnamese labels (from model)
                'B√¨nh th∆∞·ªùng': 'An to√†n',
                'Gi·∫£ m·∫°o': 'L·ª´a ƒë·∫£o',
                'Spam': 'Spam',
                'ƒê√°ng ng·ªù': 'ƒê√°ng ng·ªù',
                'Ph·∫ßn m·ªÅm ƒë·ªôc h·∫°i': 'Ph·∫ßn m·ªÅm ƒë·ªôc h·∫°i',
                'Th√¥ng b√°o': 'Th√¥ng b√°o',
                'H√≥a ƒë∆°n': 'H√≥a ƒë∆°n',
                'Khuy·∫øn m√£i': 'Khuy·∫øn m√£i',
                'An to√†n': 'An to√†n',
                'L·ª´a ƒë·∫£o': 'L·ª´a ƒë·∫£o',
                # Additional mappings for model output
                'normal': 'An to√†n',
                'fake': 'L·ª´a ƒë·∫£o',
                'suspicious': 'ƒê√°ng ng·ªù'
            }
            
            print(f"üîç Debug: Raw classification from model: '{raw_classification}'")
            print(f"üîç Debug: Available keys in map: {list(classification_map.keys())}")
            
            # Get base classification from model
            base_classification = classification_map.get(raw_classification, 'C·∫ßn xem x√©t th√™m')
            
            # Apply content-based classification rules
            classification = self._apply_content_rules(base_classification, email_text)
            
            print(f"üîç Debug: Base classification: '{base_classification}'")
            print(f"üîç Debug: Final classification: '{classification}'")
            
            # Get AI explanation using the existing Answer_Question_From_Documents
            ai_analyzer = Answer_Question_From_Documents(email_text, classification)
            explanation = ai_analyzer.run()
            
            # If AI explanation fails, provide a basic explanation
            if explanation and (explanation.startswith("‚ùå") or "kh√¥ng th·ªÉ" in explanation.lower()):
                explanation = self._generate_basic_explanation(classification, email_text)
            
            # Calculate confidence (placeholder - you might want to enhance this)
            confidence = self._calculate_confidence(email_text, classification)
            
            # Extract features for detailed analysis
            features = self._extract_features(email_text)
            
            return {
                "classification": classification,
                "confidence": confidence,
                "explanation": explanation,
                "features": features,
                "processing_time": 0,  # Will be calculated by API layer
                "risk_score": self._calculate_risk_score(classification, confidence),
                "recommendations": self._get_recommendations(classification)
            }
            
        except Exception as e:
            print(f"‚ùå Error during analysis: {e}")
            raise
    
    def _calculate_confidence(self, email_text, classification):
        """Calculate confidence score based on various factors"""
        # This is a simplified confidence calculation
        # You can enhance this based on your model's actual confidence scores
        
        base_confidence = 0.85
        
        # Adjust based on email length
        if len(email_text) < 50:
            base_confidence -= 0.1
        elif len(email_text) > 1000:
            base_confidence += 0.05
        
        # Adjust based on classification patterns
        spam_keywords = ['win', 'lottery', 'urgent', 'click here', 'free money']
        phishing_keywords = ['verify', 'account', 'suspended', 'confirm', 'login']
        
        email_lower = email_text.lower()
        spam_count = sum(1 for keyword in spam_keywords if keyword in email_lower)
        phishing_count = sum(1 for keyword in phishing_keywords if keyword in email_lower)
        
        # Map Vietnamese classification back to English for comparison
        classification_map_reverse = {
            'An to√†n': 'safe',
            'Spam': 'spam', 
            'L·ª´a ƒë·∫£o': 'phishing',
            'ƒê√°ng ng·ªù': 'suspicious',
            'Ph·∫ßn m·ªÅm ƒë·ªôc h·∫°i': 'malware',
            'C·∫ßn xem x√©t th√™m': 'unknown'
        }
        eng_classification = classification_map_reverse.get(classification, classification)
        
        if eng_classification == 'spam' and spam_count >= 2:
            base_confidence += 0.1
        elif eng_classification == 'phishing' and phishing_count >= 2:
            base_confidence += 0.1
        elif eng_classification == 'safe' and spam_count == 0 and phishing_count == 0:
            base_confidence += 0.05
        
        return min(max(base_confidence, 0.1), 0.99)
    
    def _apply_content_rules(self, base_classification, email_text):
        """Apply content-based rules to improve classification"""
        email_lower = email_text.lower()
        
        # Invoice detection
        invoice_keywords = ['invoice', 'h√≥a ƒë∆°n', 'bill', 'payment', 'amount', 'due date', 'billing']
        if any(keyword in email_lower for keyword in invoice_keywords):
            return 'H√≥a ƒë∆°n'
        
        # Notification detection
        notification_keywords = ['notification', 'th√¥ng b√°o', 'announcement', 'update', 'important notice']
        if any(keyword in email_lower for keyword in notification_keywords):
            return 'Th√¥ng b√°o'
        
        # Promotion detection
        promotion_keywords = ['promotion', 'khuy·∫øn m√£i', 'discount', 'offer', 'sale', 'limited time', 'special']
        if any(keyword in email_lower for keyword in promotion_keywords):
            return 'Khuy·∫øn m√£i'
        
        # Spam detection (override safe classification)
        spam_keywords = ['congratulations', 'winner', 'lottery', 'prize', 'free money', 'claim now', 'act now']
        if any(keyword in email_lower for keyword in spam_keywords):
            return 'Spam'
        
        # Phishing detection (override safe classification)
        phishing_keywords = ['verify', 'confirm', 'account suspended', 'login', 'password', 'security alert']
        if any(keyword in email_lower for keyword in phishing_keywords):
            return 'L·ª´a ƒë·∫£o'
        
        # Return base classification if no specific rules match
        return base_classification
    
    def _extract_features(self, email_text):
        """Extract features from email text"""
        email_lower = email_text.lower()
        
        # Check for suspicious patterns
        urgent_words = ['urgent', 'immediate', 'asap', 'now', 'quickly', 'hurry', 'congratulations']
        money_words = ['money', 'win', 'lottery', 'prize', 'million', 'dollar', '$', 'cash', '1000000']
        action_words = ['click', 'verify', 'confirm', 'download', 'login', 'password', 'claim']
        spam_words = ['free', 'limited time', 'exclusive', 'act now', 'don\'t miss', 'congratulations']
        
        # Count occurrences for better analysis
        urgent_count = sum(1 for word in urgent_words if word in email_lower)
        money_count = sum(1 for word in money_words if word in email_lower)
        action_count = sum(1 for word in action_words if word in email_lower)
        spam_count = sum(1 for word in spam_words if word in email_lower)
        

        
        return {
            "üìè ƒê·ªô d√†i email": f"{len(email_text)} k√Ω t·ª±",
            "üìù S·ªë t·ª´": f"{len(email_text.split())} t·ª´",
            "üîó C√≥ li√™n k·∫øt": "‚úÖ C√≥" if "http" in email_lower else "‚ùå Kh√¥ng",
            "‚ö° T·ª´ kh√≥a kh·∫©n c·∫•p": f"‚ö†Ô∏è C√≥ ({urgent_count} t·ª´)" if urgent_count > 0 else "‚úÖ Kh√¥ng",
            "üí∞ T·ª´ kh√≥a ti·ªÅn b·∫°c": f"üí∏ C√≥ ({money_count} t·ª´)" if money_count > 0 else "‚úÖ Kh√¥ng",
            "üéØ T·ª´ kh√≥a h√†nh ƒë·ªông": f"üîß C√≥ ({action_count} t·ª´)" if action_count > 0 else "‚úÖ Kh√¥ng",
            "üìß T·ª´ kh√≥a spam": f"üö´ C√≥ ({spam_count} t·ª´)" if spam_count > 0 else "‚úÖ Kh√¥ng"
        }
    
    def _calculate_risk_score(self, classification, confidence):
        """Calculate risk score from 0-100"""
        risk_levels = {
            'An to√†n': 0,
            'ƒê√°ng ng·ªù': 1,
            'Spam': 2,
            'L·ª´a ƒë·∫£o': 3,
            'Ph·∫ßn m·ªÅm ƒë·ªôc h·∫°i': 4,
            'C·∫ßn xem x√©t th√™m': 1
        }
        base_risk = risk_levels.get(classification, 1)
        return min(int(base_risk * confidence * 25), 100)
    
    def _generate_basic_explanation(self, classification, email_text):
        """Generate basic explanation when AI fails"""
        explanations = {
            'An to√†n': f"‚úÖ Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† An to√†n v√¨ kh√¥ng ch·ª©a c√°c d·∫•u hi·ªáu ƒë√°ng ng·ªù. B·∫°n c√≥ th·ªÉ y√™n t√¢m ƒë·ªçc v√† tr·∫£ l·ªùi email n√†y.",
            'Spam': f"üìß Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† Spam v√¨ ch·ª©a c√°c t·ª´ kh√≥a qu·∫£ng c√°o v√† l·ªùi h·ª©a kh√¥ng th·ª±c t·∫ø. Khuy·∫øn ngh·ªã x√≥a email n√†y.",
            'L·ª´a ƒë·∫£o': f"üé£ Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† L·ª´a ƒë·∫£o v√¨ y√™u c·∫ßu th√¥ng tin c√° nh√¢n ho·∫∑c c√≥ li√™n k·∫øt ƒë√°ng ng·ªù. TUY·ªÜT ƒê·ªêI KH√îNG click v√†o li√™n k·∫øt ho·∫∑c cung c·∫•p th√¥ng tin.",
            'ƒê√°ng ng·ªù': f"‚ö†Ô∏è Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† ƒê√°ng ng·ªù v√¨ c√≥ m·ªôt s·ªë d·∫•u hi·ªáu kh√¥ng b√¨nh th∆∞·ªùng. H√£y c·∫©n th·∫≠n v√† x√°c minh tr∆∞·ªõc khi h√†nh ƒë·ªông.",
            'Ph·∫ßn m·ªÅm ƒë·ªôc h·∫°i': f"ü¶† Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† Ph·∫ßn m·ªÅm ƒë·ªôc h·∫°i v√¨ c√≥ th·ªÉ ch·ª©a virus ho·∫∑c m√£ ƒë·ªôc. KH√îNG m·ªü t·ªáp ƒë√≠nh k√®m v√† x√≥a ngay l·∫≠p t·ª©c.",
            'C·∫ßn xem x√©t th√™m': f"‚ùì Email n√†y c·∫ßn xem x√©t th√™m v√¨ kh√¥ng th·ªÉ ph√¢n lo·∫°i r√µ r√†ng. H√£y ki·ªÉm tra k·ªπ tr∆∞·ªõc khi th·ª±c hi·ªán b·∫•t k·ª≥ h√†nh ƒë·ªông n√†o.",
            'Th√¥ng b√°o': f"üì¢ Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† Th√¥ng b√°o ch√≠nh th·ª©c. B·∫°n c√≥ th·ªÉ ƒë·ªçc v√† th·ª±c hi·ªán theo h∆∞·ªõng d·∫´n.",
            'H√≥a ƒë∆°n': f"üßæ Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† H√≥a ƒë∆°n thanh to√°n. H√£y ki·ªÉm tra th√¥ng tin thanh to√°n c·∫©n th·∫≠n.",
            'Khuy·∫øn m√£i': f"üéâ Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† Khuy·∫øn m√£i. H√£y ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa ch∆∞∆°ng tr√¨nh tr∆∞·ªõc khi tham gia."
        }
        return explanations.get(classification, f"üìä Email n√†y ƒë∆∞·ª£c ph√¢n lo·∫°i l√† {classification}. H√£y ki·ªÉm tra k·ªπ tr∆∞·ªõc khi th·ª±c hi·ªán b·∫•t k·ª≥ h√†nh ƒë·ªông.")
    
    def _get_recommendations(self, classification):
        """Get security recommendations based on classification"""
        recommendations = {
            'An to√†n': ['‚úÖ Email an to√†n, c√≥ th·ªÉ ƒë·ªçc v√† tr·∫£ l·ªùi b√¨nh th∆∞·ªùng'],
            'ƒê√°ng ng·ªù': [
                'üîç X√°c minh danh t√≠nh ng∆∞·ªùi g·ª≠i tr∆∞·ªõc khi tr·∫£ l·ªùi',
                '‚ö†Ô∏è Tr√°nh click v√†o c√°c li√™n k·∫øt ƒë√°ng ng·ªù',
                'üìã Ki·ªÉm tra c√°c y√™u c·∫ßu b·∫•t th∆∞·ªùng'
            ],
            'Spam': [
                'üóëÔ∏è X√≥a email ngay l·∫≠p t·ª©c',
                'üè∑Ô∏è ƒê√°nh d·∫•u l√† spam',
                '‚ùå Kh√¥ng tr·∫£ l·ªùi ho·∫∑c click v√†o b·∫•t k·ª≥ li√™n k·∫øt n√†o'
            ],
            'L·ª´a ƒë·∫£o': [
                'üö´ TUY·ªÜT ƒê·ªêI KH√îNG click v√†o b·∫•t k·ª≥ li√™n k·∫øt n√†o',
                'üîí Kh√¥ng cung c·∫•p th√¥ng tin c√° nh√¢n',
                'üìû B√°o c√°o cho ƒë·ªôi b·∫£o m·∫≠t IT',
                'üóëÔ∏è X√≥a ngay l·∫≠p t·ª©c'
            ],
            'Ph·∫ßn m·ªÅm ƒë·ªôc h·∫°i': [
                'üö® C√°ch ly ngay l·∫≠p t·ª©c',
                'üõ°Ô∏è Ch·∫°y qu√©t virus to√†n h·ªá th·ªëng',
                'üìû Li√™n h·ªá ƒë·ªôi b·∫£o m·∫≠t',
                'üìé Kh√¥ng m·ªü b·∫•t k·ª≥ t·ªáp ƒë√≠nh k√®m n√†o'
            ],
            'C·∫ßn xem x√©t th√™m': [
                'üîç Ki·ªÉm tra k·ªπ n·ªôi dung email',
                'üìß X√°c minh ngu·ªìn g·ªëc',
                '‚è∞ Kh√¥ng v·ªôi v√†ng th·ª±c hi·ªán y√™u c·∫ßu'
            ],
            'Th√¥ng b√°o': [
                'üì¢ Email th√¥ng b√°o ch√≠nh th·ª©c',
                '‚úÖ C√≥ th·ªÉ ƒë·ªçc v√† th·ª±c hi·ªán theo h∆∞·ªõng d·∫´n'
            ],
            'H√≥a ƒë∆°n': [
                'üßæ Email h√≥a ƒë∆°n thanh to√°n',
                'üí∞ Ki·ªÉm tra th√¥ng tin thanh to√°n',
                'üìÖ Ghi nh·ªõ ng√†y h·∫°n thanh to√°n'
            ],
            'Khuy·∫øn m√£i': [
                'üéâ Email khuy·∫øn m√£i t·ª´ doanh nghi·ªáp',
                'üîç Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa ch∆∞∆°ng tr√¨nh',
                '‚ö†Ô∏è C·∫©n th·∫≠n v·ªõi c√°c ∆∞u ƒë√£i qu√° h·∫•p d·∫´n'
            ]
        }
        return recommendations.get(classification, ['‚ùì C·∫ßn xem x√©t th√™m'])

# Global analyzer instance
_analyzer_instance = None

def get_analyzer():
    """Get or create the global analyzer instance"""
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = EmailAnalyzer()
    return _analyzer_instance 